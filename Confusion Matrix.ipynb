{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3989382e",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3de113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fd2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [1, 3, 3, 2, 5, 5, 3, 2, 1, 4, 3, 2, 1, 1, 2]\n",
    "predicted = [1, 2, 3, 4, 2, 3, 3, 2, 1, 2, 3, 1, 5, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb4ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the confusion matrix \n",
    "\n",
    "def confusionmatrix(actual,predicted):\n",
    "    \n",
    "    # the classes during making of confusion matrix should be unique \n",
    "    classes = np.unique(actual)\n",
    "    \n",
    "    # creating a null matrix \n",
    "    confusion_matrix = np.zeros((len(classes),len(classes)))\n",
    "    \n",
    "    # looping around the actual to predicted with nested loop to cover each combination\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            \n",
    "            confusion_matrix[i,j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n",
    "            \n",
    "    return confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34aa4a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 0., 0., 0., 1.],\n",
       "       [2., 1., 0., 1., 0.],\n",
       "       [0., 1., 3., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionmatrix(actual,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbd6575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0, 0, 1],\n",
       "       [2, 1, 0, 1, 0],\n",
       "       [0, 1, 3, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the confusion matrix using sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual,predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e41bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum = 0\n",
    "tot_sum = 0\n",
    "for i in range(0, len(cm)):\n",
    "  for j in range(0, len(cm)): \n",
    "    tot_sum += cm[i][j]\n",
    "tot_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b5431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(mat, n):\n",
    "  col_sum = [sum([row[i] for row in mat]) for i in range(0,len(mat[0]))]\n",
    "  row_sum = [sum(mat[i]) for i in range(len(mat))]\n",
    "  tp = mat[n][n]\n",
    "  fp = row_sum[n] - tp\n",
    "  fn = col_sum[n] - tp\n",
    "  tn = tot_sum - fp - fn - tp\n",
    "  param = []\n",
    "  accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "  param.append(accuracy)\n",
    "  precision = tp / (tp + fp)\n",
    "  param.append(precision)\n",
    "  recall = tp / (tp + fn)\n",
    "  param.append(recall)\n",
    "  f1_score = (2 * precision * recall) / (precision + recall)\n",
    "  param.append(f1_score)\n",
    "  return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2e8678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the class 1, the values are as follows: \n",
      "Accuracy: 0.8\n",
      "Precision: 0.75\n",
      "Recall: 0.6\n",
      "F1-Score: 0.6666666666666665\n",
      "*********************\n",
      "For the class 2, the values are as follows: \n",
      "Accuracy: 0.6\n",
      "Precision: 0.25\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "*********************\n",
      "For the class 3, the values are as follows: \n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "*********************\n",
      "For the class 4, the values are as follows: \n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: nan\n",
      "*********************\n",
      "For the class 5, the values are as follows: \n",
      "Accuracy: 0.8\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: nan\n",
      "*********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devanshi\\AppData\\Local\\Temp\\ipykernel_8872\\1318899336.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score = (2 * precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cm)):\n",
    "  print(f\"For the class {i+1}, the values are as follows: \")\n",
    "  print(f\"Accuracy: {params(cm,i)[0]}\")\n",
    "  print(f\"Precision: {params(cm,i)[1]}\")\n",
    "  print(f\"Recall: {params(cm,i)[2]}\")\n",
    "  print(f\"F1-Score: {params(cm,i)[3]}\")\n",
    "  print(\"*********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ccd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
